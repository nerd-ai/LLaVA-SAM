{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, AutoConfig\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# 初始化设备\n",
    "device_map = \"auto\"\n",
    "\n",
    "# 初始化设备\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型\n",
    "# model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "model_id = \"./llava-7b-hf\"\n",
    "# model = LlavaForConditionalGeneration.from_pretrained(\n",
    "#     model_id, \n",
    "#     torch_dtype=torch.float16, \n",
    "#     low_cpu_mem_usage=True, \n",
    "# ).to(device)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,  # 自动分配到可用的 GPU\n",
    "    offload_folder=\"offload\",  # 可选：指定离线存储路径以减少 GPU 内存占用\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义会话历史并使用 `apply_chat_template` 获取正确格式的提示\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Is this brain MRI image normal or does it have a tumor?\"},  # 文本prompt\n",
    "            {\"type\": \"image\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "# 自己加载图片\n",
    "image_file = \"/home/zhuxy/autodl-tmp/MedCLIP-SAMv2-main/biomedclip_finetuning/open_clip/src/data/brain_tumors/test_images/66.png\"\n",
    "raw_image = Image.open(image_file).convert(\"RGB\")  # 确保图片为 RGB 格式\n",
    "print(raw_image.mode)\n",
    "# 确定图像补丁大小，根据模型文档或实际结构设置\n",
    "image_patch_size = 14  # 示例值，需根据模型实际情况调整\n",
    "\n",
    "# 准备输入\n",
    "# inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(device, torch.float16)\n",
    "inputs = processor(images=raw_image, text=prompt, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化解码器\n",
    "# inputs = processor(images=raw_image, text=prompt, return_tensors='pt')\n",
    "tokenizer = processor.tokenizer\n",
    "max_generated_length = 50  # 假设最大生成长度为 20\n",
    "generated_tokens = []\n",
    "# decoder_input_ids = torch.tensor([[tokenizer.bos_token_id]]).to(device)  # BOS token as initial input\n",
    "decoder_input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# 获取输入序列的长度\n",
    "num_text_tokens = inputs[\"input_ids\"].shape[1]  # 文本 token 长度\n",
    "num_image_tokens = inputs[\"pixel_values\"].shape[2]  # 图像 token 长度\n",
    "\n",
    "decoder_input_ids = inputs[\"input_ids\"]  # 使用初始输入 ID\n",
    "# 逐步解码\n",
    "generated_attention_maps = []\n",
    "generated_token_count = 0\n",
    "\n",
    "attention_mask = inputs[\"attention_mask\"]  # 初始的 attention mask\n",
    "\n",
    "for step in range(max_generated_length):\n",
    "    print(f\"\\nStep {step + 1}/{max_generated_length}\")\n",
    "\n",
    "\n",
    "    # 执行前向传播\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            output_attentions=True  # 确保输出 attentions\n",
    "        )\n",
    "\n",
    "    # 获取生成的 token\n",
    "    # 提取 logits 和 attentions\n",
    "    logits = outputs.logits  # (batch_size, seq_len, vocab_size)\n",
    "    attentions = outputs.attentions  # (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "    print(\"The shape of attentions:\",attentions[0].shape)\n",
    "    # 获取当前生成的 token\n",
    "    next_token = logits[:, -1, :].argmax(dim=-1)\n",
    "    generated_tokens.append(next_token.item())\n",
    "    print(\"Final Generated Tokens:\", processor.decode(generated_tokens))\n",
    "\n",
    "    # 更新输入序列，拼接生成的 token\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_token.unsqueeze(-1)], dim=-1)\n",
    "    attention_mask = torch.cat([attention_mask, torch.ones_like(next_token).unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    # 检查生成结束\n",
    "    if next_token.item() == processor.tokenizer.eos_token_id:\n",
    "        print(\"Generated EOS token. Stopping generation.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tumor_token_indices(generated_tokens, processor):\n",
    "    # 将生成的 tokens 解码为文本\n",
    "    decoded_text = processor.decode(generated_tokens)\n",
    "\n",
    "    # 如果 \"tumor\" 不在文本中，直接返回 None\n",
    "    if \"tumor\" not in decoded_text:\n",
    "        return None\n",
    "\n",
    "    # 对最终文本再次进行分词（不加特殊符号）\n",
    "    # 这样获取的 token 序列应该与 generated_tokens 在逻辑上对应\n",
    "    re_encoded_ids = processor.tokenizer.encode(decoded_text, add_special_tokens=False)\n",
    "\n",
    "    # 对 \"tumor\" 进行分词\n",
    "    tumor_ids = processor.tokenizer.encode(\"tumor\", add_special_tokens=False)\n",
    "\n",
    "    # 在 re_encoded_ids 中寻找 tumor_ids 子序列的位置\n",
    "    for start_idx in range(len(re_encoded_ids) - len(tumor_ids) + 1):\n",
    "        if re_encoded_ids[start_idx:start_idx + len(tumor_ids)] == tumor_ids:\n",
    "            # 找到匹配的位置\n",
    "            return (start_idx, start_idx + len(tumor_ids) - 1)\n",
    "\n",
    "    # 如果没有找到\n",
    "    return None\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "tumor_indices = find_tumor_token_indices(generated_tokens, processor)\n",
    "if tumor_indices is not None:\n",
    "    print(f\"'tumor' found at token indices: {tumor_indices}\")\n",
    "else:\n",
    "    print(\"No 'tumor' token found in the decoded sequence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_token_indices(inputs, image_token_id=32000):\n",
    "    input_ids = inputs[\"input_ids\"]  # [batch_size, seq_length]\n",
    "    # 假设 batch_size = 1\n",
    "    image_token_indices = (input_ids[0] == image_token_id).nonzero(as_tuple=True)[0].tolist()\n",
    "    return image_token_indices\n",
    "\n",
    "def get_image_token_start_end(image_token_indices):\n",
    "    if not image_token_indices:\n",
    "        raise ValueError(\"未找到具有指定 ID 的图像 token。\")\n",
    "    \n",
    "    image_token_start = image_token_indices[0]\n",
    "    image_token_end = image_token_indices[-1] + 1  # +1 使得 slicing 是 [start, end)\n",
    "    \n",
    "    # 验证图像 token 是否连续\n",
    "    expected_indices = list(range(image_token_start, image_token_end))\n",
    "    if image_token_indices != expected_indices:\n",
    "        raise ValueError(\"图像 token 不是连续的。\")\n",
    "    \n",
    "    return image_token_start, image_token_end\n",
    "\n",
    "# 获取所有 image token 的索引\n",
    "image_token_indices = get_image_token_indices(inputs, image_token_id=32000)\n",
    "print(f\"Number of image tokens found: {len(image_token_indices)}\")\n",
    "print(f\"Image Token Indices: {image_token_indices}\")\n",
    "\n",
    "# 获取 image_token_start 和 image_token_end\n",
    "try:\n",
    "    image_token_start, image_token_end = get_image_token_start_end(image_token_indices)\n",
    "    print(f\"Image Token Start Index: {image_token_start}\")\n",
    "    print(f\"Image Token End Index: {image_token_end}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tumor_indices is not None:\n",
    "    start_index = tumor_indices[0] + num_text_tokens # 第一个元素（整数）\n",
    "    end_index = tumor_indices[1] + num_text_tokens+1   # 第二个元素（整数）\n",
    "    # 这里的 start_index 和 end_index 就是整数类型了\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sum_attention = sum(attentions)  # 自动逐元素求和\n",
    "\n",
    "# 求平均值\n",
    "final_attention_map = sum_attention / len(attentions)\n",
    "batch_size, num_heads, seq_len, _ = final_attention_map.shape\n",
    "\n",
    "\n",
    "# 提取所有 generated_token 对 image_tokens 的注意力\n",
    "feature_attention_map_all = final_attention_map[:, :, num_text_tokens:seq_len, image_token_start+1:image_token_end+1]\n",
    "feature_attention_map_mean = feature_attention_map_all.mean(dim=(2))\n",
    "# 提取特定token处对image_token的注意力并减去所有token的平均注意力\n",
    "final_generated_token_attention = final_attention_map[:, :, start_index:end_index, image_token_start+1:image_token_end+1].mean(dim=(2))-feature_attention_map_mean\n",
    "print(final_generated_token_attention.shape)\n",
    "# 对所有头和所有生成 token 取平均\n",
    "final_image_attention_avg = final_generated_token_attention.mean(dim=(1))\n",
    "print(final_image_attention_avg)\n",
    "\n",
    "# # 初始化二维注意力图为 24x24 的零张量\n",
    "final_attention_map_2d = torch.zeros(24, 24).to(final_image_attention_avg.device)\n",
    "attention_np = final_image_attention_avg.squeeze(0).cpu().numpy()\n",
    "\n",
    "# 如果需要将 torch.Tensor 转换为 NumPy 数组进行后续处理或可视化\n",
    "# final_attention_map_2d_np = final_attention_map_2d.cpu().numpy()\n",
    "final_attention_map_2d_np = attention_np.reshape(24, 24)\n",
    "\n",
    "# 打印或使用 final_attention_map_2d_np 进行可视化\n",
    "print(final_attention_map_2d_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将注意力映射到原始像素空间\n",
    "# # 确保最终注意力图为 float32 类型\n",
    "# final_attention_map_2d = final_attention_map_2d.astype(np.float32)\n",
    "final_attention_map_2d_np = final_attention_map_2d_np.astype(np.float32)\n",
    "original_size = raw_image.size  # (W, H)\n",
    "print(raw_image.size)\n",
    "heatmap_pil = Image.fromarray(final_attention_map_2d_np)\n",
    "heatmap_resized = heatmap_pil.resize(original_size, resample=Image.BICUBIC)\n",
    "raw_heatmap = np.array(heatmap_resized)\n",
    "\n",
    "# # 应用均值滤波平滑\n",
    "# kernel_size = 7  # 定义核大小\n",
    "# final_heatmap = cv2.blur(raw_heatmap, (kernel_size, kernel_size))\n",
    "final_heatmap = raw_heatmap\n",
    "# 归一化到 [0, 255]\n",
    "normalized_heatmap = (final_heatmap - final_heatmap.min()) / (final_heatmap.max() - final_heatmap.min())\n",
    "heatmap_uint8 = (normalized_heatmap * 255).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建热力图\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(heatmap_uint8, cmap='jet')  # 使用 jet 颜色映射\n",
    "plt.colorbar()  # 添加颜色条\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是method 3 获取heatmap的方法(待定)\n",
    "# 以下是我用了hook获取每一层的query 和key来计算文章中提到的similiarity matrix，实际上可能这个就是attention matrix（需查验）\n",
    "# =================== 3. 定义钩子函数 =====================\n",
    "def cache_qk(name, module, output, cache_dict):\n",
    "    \"\"\"缓存特定模块的 Query 和 Key，并记录层数\"\"\"\n",
    "    # 使用正则表达式提取层数，确保仅匹配 language_model 的模块\n",
    "    match = re.search(r'language_model\\.model\\.layers\\.(\\d+)\\.self_attn', name)\n",
    "    if match:\n",
    "        layer_num = int(match.group(1))  # 提取层数\n",
    "    else:\n",
    "        layer_num = -1  # 未找到层数\n",
    "\n",
    "    if layer_num == -1:\n",
    "        print(f\"Skipping module: {name}\")\n",
    "        return  # 不处理未识别的层\n",
    "\n",
    "    if \"self_attn.q_proj\" in name:\n",
    "        print(f\"Caching Query for: {name}, Layer: {layer_num}, Output Shape: {output.shape}\")\n",
    "        # 将输出移动到主 GPU (GPU 0)\n",
    "        cache_dict[\"queries\"].append((layer_num, output.detach().to(\"cuda:0\")))\n",
    "    elif \"self_attn.k_proj\" in name:\n",
    "        print(f\"Caching Key for: {name}, Layer: {layer_num}, Output Shape: {output.shape}\")\n",
    "        # 将输出移动到主 GPU (GPU 0)\n",
    "        cache_dict[\"keys\"].append((layer_num, output.detach().to(\"cuda:0\")))\n",
    "    else:\n",
    "        print(f\"Skipping module: {name}\")\n",
    "\n",
    "def register_hooks(model, cache_dict, total_layers=32):\n",
    "    hook_handles = []  # 用于存储钩子对象\n",
    "\n",
    "    # 遍历所有模块\n",
    "    for name, module in model.named_modules():\n",
    "        # 仅匹配 language_model 中的 self_attn.q_proj 和 self_attn.k_proj\n",
    "        if 'language_model.model.layers.' in name and ('self_attn.q_proj' in name or 'self_attn.k_proj' in name):\n",
    "            # 注册钩子，使用当前模块名称作为默认参数，避免闭包问题\n",
    "            handle = module.register_forward_hook(\n",
    "                lambda module, input, output, name=name: cache_qk(\n",
    "                    name,\n",
    "                    module,\n",
    "                    output,\n",
    "                    cache_dict\n",
    "                )\n",
    "            )\n",
    "            hook_handles.append(handle)\n",
    "            print(f\"Hook registered for: {name}\")\n",
    "\n",
    "    print(\"All hooks registered for language_model's self_attn.q_proj and self_attn.k_proj.\")\n",
    "    print(f\"Total hooks registered: {len(hook_handles)}\")\n",
    "    return hook_handles\n",
    "# 初始化解码器\n",
    "tokenizer = processor.tokenizer\n",
    "max_generated_length = 30  # 假设最大生成长度为 20\n",
    "generated_tokens = []\n",
    "# decoder_input_ids = torch.tensor([[tokenizer.bos_token_id]]).to(device)  # BOS token as initial input\n",
    "decoder_input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# 获取输入序列的长度\n",
    "num_text_tokens = inputs[\"input_ids\"].shape[1]  # 文本 token 长度\n",
    "num_image_tokens = inputs[\"pixel_values\"].shape[2]  # 图像 token 长度\n",
    "\n",
    "decoder_input_ids = inputs[\"input_ids\"]  # 使用初始输入 ID\n",
    "# 逐步解码\n",
    "generated_attention_maps = []\n",
    "generated_token_count = 0\n",
    "\n",
    "cache_dict = {\"queries\": [], \"keys\": []}\n",
    "hook_handles = register_hooks(model, cache_dict,32)\n",
    "attention_mask = inputs[\"attention_mask\"]  # 初始的 attention mask\n",
    "\n",
    "for step in range(max_generated_length):\n",
    "    print(f\"\\nStep {step + 1}/{max_generated_length}\")\n",
    "\n",
    "    # 清空当前步的缓存\n",
    "    cache_dict[\"queries\"].clear()\n",
    "    cache_dict[\"keys\"].clear()\n",
    "\n",
    "    # 执行前向传播\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            output_attentions=True  # 确保输出 attentions\n",
    "        )\n",
    "\n",
    "    # 验证缓存结果\n",
    "    num_queries_cached = len(cache_dict[\"queries\"])\n",
    "    num_keys_cached = len(cache_dict[\"keys\"])\n",
    "    print(f\"Number of Queries Cached: {num_queries_cached}\")\n",
    "    if cache_dict[\"queries\"]:\n",
    "        for i, (layer_num, q) in enumerate(cache_dict[\"queries\"]):\n",
    "            print(f\"Query {i+1}: Layer {layer_num}, Shape: {q.shape}, Device: {q.device}\")\n",
    "    else:\n",
    "        print(\"No Queries Cached!\")\n",
    "\n",
    "    print(f\"Number of Keys Cached: {num_keys_cached}\")\n",
    "    if cache_dict[\"keys\"]:\n",
    "        for i, (layer_num, k) in enumerate(cache_dict[\"keys\"]):\n",
    "            print(f\"Key {i+1}: Layer {layer_num}, Shape: {k.shape}, Device: {k.device}\")\n",
    "    else:\n",
    "        print(\"No Keys Cached!\")\n",
    "\n",
    "    # 获取生成的 token\n",
    "    # 提取 logits 和 attentions\n",
    "    logits = outputs.logits  # (batch_size, seq_len, vocab_size)\n",
    "    attentions = outputs.attentions  # (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "    # 获取当前生成的 token\n",
    "    next_token = logits[:, -1, :].argmax(dim=-1)\n",
    "    generated_tokens.append(next_token.item())\n",
    "    print(\"Final Generated Tokens:\", processor.decode(generated_tokens))\n",
    "\n",
    "    # 更新输入序列，拼接生成的 token\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_token.unsqueeze(-1)], dim=-1)\n",
    "    attention_mask = torch.cat([attention_mask, torch.ones_like(next_token).unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    # 检查生成结束\n",
    "    if next_token.item() == processor.tokenizer.eos_token_id:\n",
    "        print(\"Generated EOS token. Stopping generation.\")\n",
    "        break\n",
    "\n",
    "    # 释放不需要的变量\n",
    "    del outputs, next_token,logits,attentions\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 移除钩子\n",
    "for handle in hook_handles:\n",
    "    handle.remove()\n",
    "hook_handles.clear()\n",
    "\n",
    "print(\"All hooks have been removed.\")\n",
    "print(\"Final Generated Tokens:\", tokenizer.decode(generated_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 重塑 Queries 和 Keys =====================\n",
    "# 定义多头设置\n",
    "import math\n",
    "num_heads = 32  # 根据模型配置\n",
    "hidden_dim = 4096  # 总隐藏维度\n",
    "head_dim = hidden_dim // num_heads  # 128\n",
    "# scale = head_dim ** 0.5  # 缩放因子\n",
    "scale = math.sqrt(hidden_dim)  # 缩放因子\n",
    "\n",
    "num_layers_captured = 32\n",
    "\n",
    "# 初始化列表来存储重塑后的 queries 和 keys\n",
    "reshaped_queries = []\n",
    "reshaped_keys = []\n",
    "\n",
    "for layer_idx in range(num_layers_captured):\n",
    "    q = cache_dict[\"queries\"][layer_idx][1]  # [1, seq_len, hidden_dim]\n",
    "    k = cache_dict[\"keys\"][layer_idx][1]     # [1, seq_len, hidden_dim]\n",
    "\n",
    "    # 重塑为 [batch_size, num_heads, seq_len, head_dim]\n",
    "    q = q.view(q.size(0), q.size(1), num_heads, head_dim).transpose(1, 2)  # [1, H, N, D]\n",
    "    k = k.view(k.size(0), k.size(1), num_heads, head_dim).transpose(1, 2)  # [1, H, N, D]\n",
    "\n",
    "    # 移除 batch 维度\n",
    "    q = q.squeeze(0)  # [H, N, D]\n",
    "    k = k.squeeze(0)  # [H, N, D]\n",
    "\n",
    "    reshaped_queries.append(q)  # 列表长度为 num_layers, 每个元素 [H, N, D]\n",
    "    reshaped_keys.append(k)\n",
    "\n",
    "# 转换为 Tensor，形状为 [num_layers, num_heads, seq_len, head_dim]\n",
    "reshaped_queries = torch.stack(reshaped_queries, dim=0)  # [L, H, N, D]\n",
    "reshaped_keys = torch.stack(reshaped_keys, dim=0)        # [L, H, N, D]\n",
    "\n",
    "print(f\"Shape of reshaped queries: {reshaped_queries.shape}\")  # [32, 32, 612, 128]\n",
    "print(f\"Shape of reshaped keys: {reshaped_keys.shape}\")        # [32, 32, 612, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 13. 计算 Similarity Matrix S =====================\n",
    "# S ∈ [N, N, H, L]\n",
    "N = reshaped_queries.size(2)  # seq_len\n",
    "H = reshaped_queries.size(1)  # 32\n",
    "L = reshaped_queries.size(0)  # num_layers\n",
    "\n",
    "# 初始化 S\n",
    "S = torch.zeros((N, N, H, L), device=\"cuda:1\")  # [seq_len, seq_len, H, L]\n",
    "\n",
    "for layer_idx in range(L):\n",
    "    for head_idx in range(H):\n",
    "        q = reshaped_queries[layer_idx, head_idx, :, :]  # [N, D]\n",
    "        k = reshaped_keys[layer_idx, head_idx, :, :]     # [N, D]\n",
    "\n",
    "        # 计算相似度\n",
    "        scores = torch.matmul(q, k.transpose(0, 1)) / scale  # [N, N]\n",
    "\n",
    "        # 应用因果掩码\n",
    "        causal_mask = torch.tril(torch.ones((N, N), device=\"cuda:0\")).bool()  # [N, N]\n",
    "        scores = scores.masked_fill(~causal_mask, float('-inf'))\n",
    "\n",
    "        # 应用 Softmax\n",
    "        similarity_map = torch.softmax(scores, dim=-1)  # [N, N]\n",
    "        # 存储到 S\n",
    "        S[:, :, head_idx, layer_idx] = similarity_map  # [N, N, H, L]\n",
    "\n",
    "print(f\"Shape of similarity matrix S: {S.shape}\")  # [N, N, H, L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 14. 计算聚合权重 W =====================\n",
    "# W ∈ [1, 1, H, L]\n",
    "\n",
    "# 计算 Max(S, dim=1)\n",
    "# S: [N, N, H, L]\n",
    "Max_S, _ = S.max(dim=1)  # [N, H, L]\n",
    "\n",
    "# 计算 Mean(Max_S, dim=0)\n",
    "W = Max_S.mean(dim=0)  # [H, L]\n",
    "\n",
    "# 调整形状为 [1, 1, H, L]\n",
    "W = W.unsqueeze(0).unsqueeze(0)  # [1, 1, H, L]\n",
    "\n",
    "print(f\"Shape of attention head weights W: {W.shape}\")  # [1, 1, H, L]\n",
    "\n",
    "# =================== 15. 可视化 W =====================\n",
    "# # 可视化 W 的部分内容，例如第一个头和第一层\n",
    "# if W.numel() > 0:\n",
    "#     H_idx = 0\n",
    "#     L_idx = 0\n",
    "#     W_val = W[0, 0, H_idx, L_idx].item()\n",
    "#     print(f\"Attention Weight W for Head {H_idx + 1}, Layer {L_idx + 1}: {W_val}\")\n",
    "\n",
    "#     # 可视化 W 的某个特定头和层\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     plt.bar(range(H), W[0, 0, :, L_idx].cpu().numpy())\n",
    "#     plt.xlabel('Head Index')\n",
    "#     plt.ylabel('Attention Weight')\n",
    "#     plt.title(f'Attention Weights for Layer {L_idx + 1}')\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"Attention head weights W is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保 W 位于与 S 相同的设备上 (cuda:1)\n",
    "S_prime = (S * W).mean(dim=2)  # S_prime: [N, N, L]\n",
    "# =================== 16. 计算 Attention Rollout =====================\n",
    "\n",
    "# 获取 N, L\n",
    "N = S_prime.size(0)  # seq_len\n",
    "L = S_prime.size(2)  # num_layers\n",
    "\n",
    "# 定义设备，确保与 S_prime 相同\n",
    "device = S_prime.device\n",
    "\n",
    "# 初始化单位矩阵 I\n",
    "I = torch.eye(N, device=device)\n",
    "\n",
    "# 初始化累积注意力矩阵 S_rollout 为单位矩阵\n",
    "S_rollout = I.clone()\n",
    "\n",
    "print(\"Starting Attention Rollout computation...\")\n",
    "\n",
    "# 递归计算累积注意力矩阵\n",
    "for l in range(L):\n",
    "    print(f\"Processing layer {l + 1}/{L}\")\n",
    "    \n",
    "    # 获取当前层的 S_prime\n",
    "    S_prime_l = S_prime[:, :, l]  # [N, N]\n",
    "    \n",
    "    # 计算 (I + S_prime^l)\n",
    "    A_l = I + S_prime_l  # [N, N]\n",
    "    \n",
    "    # 更新 S_rollout: A_l @ S_rollout\n",
    "    S_rollout = torch.matmul(A_l, S_rollout)  # [N, N]\n",
    "    \n",
    "    # # 可选：归一化 S_rollout 或其他操作\n",
    "    # # 例如，可以按行归一化\n",
    "    # S_rollout = S_rollout / S_rollout.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    print(f\"S_rollout after layer {l + 1}: {S_rollout.shape}\")\n",
    "\n",
    "print(\"Attention Rollout computation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # j 从 1 到 N，对应于索引 0 到 N-1 (这步是正则化操作 (待定))\n",
    "multiplier = ((torch.arange(N, device=device).float()+1) / N)  # [N]\n",
    "\n",
    "# # 调整形状为 [1, N] 以便与 S_rollout 进行逐列相乘\n",
    "# multiplier = multiplier.unsqueeze(0)  # [1, N]\n",
    "# # print(multiplier)\n",
    "# # 应用正则化项\n",
    "S_rollout_reg = S_rollout*multiplier # [N, N]\n",
    "# S_rollout_reg = S_rollout\n",
    "# print(\"Applied regularization to S_rollout.\")\n",
    "# print(f\"Shape of regularized S_rollout: {S_rollout_reg.shape}\")  # [N, N]\n",
    "# print(S_rollout_reg[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中generated_token_index 是对应想要的那几个token的index(怎么获取参照上一个方法)，如果是多个下面这个需要对第0维取平均，image_token_start(end)的获取与上一个方法的相同\n",
    "image_tokens_attention = S_rollout_reg[generated_token_index, image_token_start:image_token_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 24\n",
    "\n",
    "assert image_tokens_attention.size(0) == grid_size * grid_size, \\\n",
    "    f\"Expected {grid_size * grid_size} image tokens, but got {image_tokens_attention.size(0)}.\"\n",
    "\n",
    "# 将 1D 向量重塑为 2D 网格\n",
    "attention_grid = image_tokens_attention.view(grid_size, grid_size)  # [24, 24]\n",
    "\n",
    "print(f\"Shape of attention_grid: {attention_grid.shape}\")  # [24, 24]\n",
    "\n",
    "# =================== 5. 插值到原始图像大小 =====================\n",
    "# 将 attention_grid 转换为 [1, 1, H, W] 的形状以便插值\n",
    "attention_grid = attention_grid.unsqueeze(0).unsqueeze(0)  # [1, 1, 24, 24]\n",
    "\n",
    "# 获取原始图像的尺寸\n",
    "original_width, original_height = raw_image.size  # (width, height)\n",
    "\n",
    "# 使用插值将 attention_grid 调整到原始图像大小\n",
    "attention_resized = F.interpolate(attention_grid, size=(original_height, original_width), mode='bilinear', align_corners=False)  # [1, 1, H, W]\n",
    "\n",
    "# 移除多余的维度\n",
    "attention_resized = attention_resized.squeeze(0).squeeze(0)  # [original_height, original_width]\n",
    "\n",
    "print(f\"Shape of attention_resized: {attention_resized.shape}\")  # [original_height, original_width]\n",
    "\n",
    "# =================== 6. 应用平滑滤波 =====================\n",
    "# 将 attention_resized 转换为 NumPy 数组\n",
    "attention_np = attention_resized.cpu().numpy()\n",
    "\n",
    "# 应用高斯平滑\n",
    "kernel_size = (3, 3)  # 根据需要调整\n",
    "sigma = 1.0\n",
    "\n",
    "# 使用 OpenCV 进行高斯滤波\n",
    "attention_smoothed = cv2.GaussianBlur(attention_np, kernel_size, sigma)\n",
    "\n",
    "print(f\"Shape of attention_smoothed: {attention_smoothed.shape}\")  # [original_height, original_width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 7. 归一化并保存为红蓝热图 =====================\n",
    "# 归一化 attention_smoothed 到 [0, 1]\n",
    "min_val = attention_smoothed.min()\n",
    "max_val = attention_smoothed.max()\n",
    "if max_val - min_val != 0:\n",
    "    attention_normalized = (attention_smoothed - min_val) / (max_val - min_val)\n",
    "else:\n",
    "    attention_normalized = np.zeros_like(attention_smoothed)\n",
    "\n",
    "# 定义红蓝色调的颜色映射\n",
    "cmap = plt.get_cmap('bwr')  # 'bwr' 是蓝-白-红色映射\n",
    "\n",
    "# 将归一化的热图转换为 RGB 图像\n",
    "attention_colored = cmap(attention_normalized)[:, :, :3]  # 去除 alpha 通道\n",
    "\n",
    "# 转换为 uint8 类型\n",
    "attention_uint8 = (attention_colored * 255).astype(np.uint8)\n",
    "\n",
    "# 将 NumPy 数组转换为 PIL Image\n",
    "attention_image = Image.fromarray(attention_uint8)\n",
    "# 后续可以进行可视化操作或者保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava-med_",
   "language": "python",
   "name": "llava-med"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
